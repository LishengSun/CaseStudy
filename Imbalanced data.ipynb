{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some studies in imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div><div class=\"cite2c-biblio\"></div>I log my studies and thoughts about the imbalanced data problem in machine learning. To simplify the discussion, I will first restrict myself to binary classification problem. \n",
    "\n",
    "## The problem\n",
    "<strong>Definition</strong>: A dataset is imbalanced if the classification categories are not approximately equally represented. (#cite-chawla2009data).           \n",
    "\n",
    "<strong>Example</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 1: 104 instances\n",
      "y = 0: 896 instances\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, weights=[0.9, 0.1])\n",
    "print ('y = 1: %i instances'%list(y).count(1))\n",
    "print ('y = 0: %i instances'%list(y).count(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Do we really want to balance it?\n",
    "In general, we can upsample (the minority class) or downsample (the majority class) to balance the data. But resampling usually introduces bias. Other possibility is to use boosting, some learning machine has this built-in functionality (RF, XGBoost, etc.) to focus the learning in mis-classified instances. \n",
    "\n",
    "## Metric choice: What do we really care about? \n",
    "The performance of a classifier can be measured by confusion matrix, in which, based on the predictions and ground-truth, we can define TP, TN, FP and FN. Other metrics can then be derived:                  \n",
    "<strong>Accuracy</strong> \n",
    "          $$ =\\frac{TP+TN}{TP+FP+TN+FN} $$ \n",
    "- Not appropriate: can be over optimal (for example, a constant classifier can always predict 0 and still get a high accuracy ~0.9).     \n",
    "\n",
    "<strong>ROC and ROC-AUC</strong>           \n",
    "- x axis: $$ FPR = \\frac{FP}{FP + TN} $$\n",
    "- y axis: $$ TPR = \\frac{TP}{TP + FN} $$\n",
    "- perfect predictor: (0, 1)\n",
    "- In the ROC curve, one point is one predict probability threshold, the curve tracks different thresholds. Its AUC is then independent of those thresholds and give an overall measure of performance.\n",
    "- Not appropriate for very imbalanced data, because both FPR and TPR depends on TN, which usually is weighted less in our decision (image predicting a financial crisis, where most instances are negative, i.e. no crisis, in this case, predicting correctly a person with no crisis is less important). And a high ROC-AUC can achieve a low value when maximizing TN. Same reasoning for the dependence of FN in the y axis.\n",
    "    \n",
    "<strong>Precision-Recall and PR-AUC</strong>        \n",
    "- Recall = $$\\frac{TP}{TP + FN}$$, over all positive instances, how many does the predictor correctly predict?\n",
    "- Precision = $$\\frac{TP}{TP + FP}$$, over all the predictor predicts as positive, how many are correct?\n",
    "- perfect predictor (1, 1)\n",
    "- bad predictor, for example, if constantly predicts 1, P/P+N~0.1 for all recall values\n",
    "- good when very imbalanced, no dependence of TN, only concern with TP.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{% bibliography %}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<!--bibtex\n",
    "\n",
    "@incollection{chawla2009data,\n",
    "  title={Data mining for imbalanced datasets: An overview},\n",
    "  author={Chawla, Nitesh V},\n",
    "  booktitle={Data mining and knowledge discovery handbook},\n",
    "  pages={875--886},\n",
    "  year={2009},\n",
    "  publisher={Springer}\n",
    "}\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
